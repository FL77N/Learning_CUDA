# 4.1 CUDA内存模型概述

## 4.1.1 内存层次结构的优点

应用程序往往遵循局部性原则，**即可以在任意时间点访问相对较小的局部地址空间**

有两种类型局部性

- 时间局部性认为如果一个数据位置被引用，那么该数据在较短的时间周期内很可能会再次被引用
- 空间局部性认为如果一个内存位置被引用，则附近的位置也可能被引用

CPU和GPU的主存都采用的是DRAM（动态随机存取存储器），而低延迟内存（CPU一级缓存）使用的则是SRAM（静态随机存取存储器）。当数据被处理器频繁使用时，该数据保存在低延迟，低容量的存储器中；如果只是被存储以备后用时，数据就存储在高延迟，大容量的存储器中。

## 4.1.2 CUDA内存模型

一般来说，存储器分为可编程和不可编程，在CPU中，一级缓存和二级缓存都是不可编程的存储器。在CUDA中，可编程内存类型如下

- 寄存器
- 共享内存
- 本地内存
- 常量内存
- 纹理内存
- 全局内存

具体来说：

1. 一个核函数中的线程都有自己**私有的本地内存**
2. 一个线程块有自己的 **共享内存**，对同一线程块的所有线程都可见
3. 所有线程都可以访问全局内存
4. 所有线程都能访问的 **只读内存空间**有：常量内存空间和纹理内存
5. 纹理内存为各种数据布局提供了不同的寻址模式和滤波模式

### 4.1.2.1 寄存器

寄存器是GPU上运行速度最快的内存空间，核函数声明的一个没有其他修饰符的自变量，**通常存储在寄存器中**

在核函数声明的数组中，**如果引用该数组的索引是常量且能在编译时确定**，那么该数组也存储在寄存器中



寄存器变量对于每个线程来说是私有的，一个核函数通常用寄存器来保存频繁访问的线程私有变量。 寄存器变量与核函数生命周期相同，即一旦核函数执行完毕，就不能访问寄存器变量



寄存器是一个在SM中由活跃线程束划分出的较少资源，**在核函数中使用较少的寄存器将使在SM上有更多的常驻线程块**。每个SM上并发线程块越多，使用率和性能越高



如果一个核函数使用了超过硬件限制数量的寄存器，则会用**本地内存**替代多占用的寄存器。为了避免寄存器溢出带来的不利影响，nvcc编译器会使用启发式策略最小化寄存器使用。我们也可以给每个核函数显式加上信息帮助编译器优化

```cpp
__global__ void 
__launch_bounds__(maxThreadsPerBlock, minBlocksPerMultiprocessor)
kernel(...){
    ...
}
```

maxThreadsPerBlock指的是每个线程块可以包含的最大线程数，minBlocksPerMultiprocessor指的是每个SM中预期的最小的常驻线程块数量。

我们也可以用`maxrrecount`编译选项，指定所有核函数使用寄存器的最大数量

### 4.1.2.2 本地内存

编译器可能存放到本地内存中的变量有：

- 在编译时使用未知索引引用的本地数组
- 可能会占用大量寄存器空间的较大本地结构体或数组
- 任何不满足核函数寄存器限定条件的变量

溢出到本地内存中的变量本质上与全局内存在同一块存储区域，因此本地内存访问的特点是高延迟和低带宽

### 4.1.2.3 共享内存

核函数中使用 `__shared__`修饰符修饰的变量存放在共享内存中

它具有更高的带宽和更低的延迟。每一个SM都有一定数量的由线程块分配的共享内存，因此如果过度使用共享内存，则会限制活跃线程束的数量

虽然共享内存在核函数范围内声明，但是其生命周期伴随着整个线程块。**一个线程块执行结束后，其分配的共享内存将被释放并重新分配给其他线程块**

共享内存是线程之间相互通信的基本方式，一个块内的线程通过共享内存进行合作，前提是同步使用以下调用

`__syncthreads()`，该函数保证所有线程在其他线程被允许执行前，到达该处。当然这个函数强制SM到空闲状态，会影响性能

### 4.1.2.4 常量内存

常量内存驻留在设备内存中，并在每个SM专用的常量缓存中缓存。使用如下修饰符来修饰：

`__constant__`

常量变量必须在**全局空间内和所有核函数之外**进行声明，对所有计算能力的设备只可以声明64KB的内存，对同一编译单元的所有核函数可见

核函数对于常量内存的操作只有**读**，常量内存需要在**主机端**使用下面的函数来初始化

```cpp
cudaError_t cudaMemcpyToSymbol(const void* symbol, const void* src, size_t count)
```

线程束中的所有线程从相同的内存地址中读取数据时，常量内存表现最好。

### 4.1.2.5 纹理内存

忽略

### 4.1.2.6 全局内存

全局内存是GPU中最大，延迟最高且最常使用的内存。

它的声明可以在任何SM设备上被访问到，并且贯穿应用程序的整个生命周期



全局内存变量可以被静态声明或动态声明。在设备代码中，静态地声明一个变量：

`__device__`

动态分配就是之前cudaMalloc那套

全局内存分配空间存在于应用程序的整个生命周期中，并且可以访问所有核函数中的所有线程。由于线程的执行不能跨线程块同步，**不同块内的线程并发修改全局内存的同一位置会出现问题**



全局内存常驻于设备内存中，可通过32/64/128字节的内存事务进行访问，**这些内存事务需要自然对齐**，即首地址必须是32/64/128字节的倍数

一般情况下，用来满足内存请求的事务越多，未使用的字节被传输回的可能性越高，这就造成数据吞吐量降低

